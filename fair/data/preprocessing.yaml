timelines:
  tools:
    - 'sleuthkit'
    - 'plaso-tools'
  cheat_sheet:
    - description: 'Create disk timeline TSK'
      command: 'fls -{F,D}rph{u,d} -m ''/''  disk.raw | tee fls_{files,folders}_{allocated,deleted}.body && mactime -d -y -b fls_files.body | tee mactime_timeline_files.csv'
    - description: 'Create disk timeline L2T'
      command: 'log2timeline --parsers mft --storage-file /data_dst/l2t_mft.plaso /data_src/disk.raw && psort -o l2tcsv -w /data_dst/l2t_mft.csv /data_dst/l2t_mft.plaso'
    - description: 'Create windows events timeline'
      command: 'py_fair scripts windows extract_evtx -e <evtx/folder> -d <output/folder>'
    - description: 'Create activity timeline'
      command: 'log2timeline --parsers win_timeline --data /data_dst/ --process_archives --partitions all --status-view linear --logfile /data_dst/l2t_timeline.log.gz --debug --storage-file /data_dst/l2t_timeline.plaso /data_src/disk.raw && psort --status-view linear --debug --logfile /data_dst/psort_timeline.log.gz -o json_line -w /data_dst/l2t_timeline.ndjson /data_dst/l2t_timeline.plaso'
    - description: 'Merge timelines (fls, evtx, plaso)'
      command: 'py_fair scripts windows merge_timelines --timeline_evtx evtx.ndjson --timeline_plaso l2t_timeline.ndjson --timeline_fls fls.csv -d <outfolder>'
    - description: 'Upload timelines to ELK'

known_bads:
  tools:
    - 'yara'
    - 'clamscan'
    - 'nsrl'

  cheat_sheet:
    - description: 'Check files against clamav db'
      command: 'freshclam --show-progress && clamscan -r --alert-macros=yes --infected --log=clamav_infected.txt <mount_point>'
    - description: 'Check disk against a set of yara rules'
      command: 'yara -r -p 6 ruleset.yara <file|dir|pid> | tee yara.log'
    - description: 'Prepare known goods (OS and Office Suite related files) from NSRL db'
      command: 'py_fair scripts nsrl prepare --os <operating system> -n <NSRL iso mount point> -d <outdir>'
    - description: 'Thin disk timeline based on a NSRL db'
      command: 'py_fair scripts nsrl thin --body <fls_w_md5.body> --nsrl <nsrl_os.csv> -d <outdir>'
    - description: 'Look for known suspicious filenames (LotL, old tricks, tools, ...)'
      command: 'cat fls.csv | grep -Fif wordlist_windows_disk.txt'
    - description: 'Look for known suspicious executions'
      command: 'cat fls.csv grep -Fif wordlist_windows_execution.txt'
    - description: 'Look for unusual binary types in Windows user profile'
      command: 'find Users/ -type f | egrep -i ''\.(ps1|bat|vba|vbs|dll|exe|msi|hta)'' > userprofile_binaries_scripts.txt'
    - description: 'Online databases to check hashes against'
      command: 'virustotal, py_fair scripts nsrl, any.run, hybrid-analysis, tria.ge, labs.inquest.net'
    - description: 'List big files'
      command: 'find <mount point> -type f -size +10M -exec ls -lh {} \; > files_bigger_than_10M.txt'
    - description: 'List files modified recently'
      command: 'find <mount point> -type f -mtime -30 -exec ls -lh {} \; > modified_last_30d.txt'
    - description: 'List files potentially downloaded in Windows'
      command: 'find . -type f -name ''*:Zone.Identifier'' > files_with_zone_identifier.txt'

windows:
  tools:
    - 'libvshadow'
    - 'sleuthkit'
    - 'https://github.com/poorbillionaire/usn-journal-parser'
    - 'regipy (python module)'
    - 'reglookup'
    - 'yarp'
    - 'plaso-tools'
    - 'libscca'

  cheat_sheet:
    - description: 'extract $Extend\$UsnJournal:$J (determine inode from fls output)'
      command: 'icat -h -o <partition sector offset> disk.raw <inode> > usnjrnl.dat'
    - description: 'parse $Extend\$UsnJournal:$J'
      command: 'python3 usn.py -c -f usnjrnl.dat -o usnjrnl.csv'
    - description: 'clean dirty hives (SOFTWARE, SYSTEM, SAM, NTUSER.DAT, USRCLASS.DAT)'
      command: 'registry-transaction-logs <hive> -p <hive>.LOG1 -s <hive>.LOG2 -o <hive>_CLEAN'
    - description: 'dump all registries (SOFTWARE hive is big and can take up to 2 hours)'
      command: 'registry-dump -o registries.json <path to clean hives>'
    - description: 'profile a host with py_fair'
      command: 'py_fair scripts windows profile_host -o csv -e evtx.ndjson --hsystem <system hive> --hsoftware <software hive> --hsam <sam hive> -d <output/folder>'
    - description: 'profile users with py_fair'
      command: 'py_fair scripts windows profile_users -o csv -d <output/folder> --hsystem <system hive> --huser <ntuser1.dat username1> --huser <ntuser2.dat username2>'
    - description: 'Extract not-timestamped artifacts with plaso'
      command: 'log2timeline --parsers win_static --data /data_dst/ --process_archives --status-view linear --logfile /data_dst/l2t_static.log.gz --debug --storage-file /data_dst/l2t_static.plaso /data_src/disk.raw && psort --status-view linear --debug --logfile /data_dst/psort_static.log.gz -o json_line -w /data_dst/l2t_static.ndjson /data_dst/l2t_static.plaso'
    - description: 'Extract Web and Cloud artifacts'
      command: 'log2timeline --parsers win_web_and_cloud --data /data_dst/ --process_archives --status-view linear --logfile /data_dst/l2t_web_cloud.log.gz --debug --storage-file /data_dst/l2t_web_cloud.plaso /data_src/disk.raw && psort --status-view linear --debug --logfile /data_dst/psort_web_cloud.log.gz -o json_line -w /data_dst/l2t_web_cloud.ndjson /data_dst/l2t_web_cloud.plaso'
    - description: 'Carve files from disk raw/hyberfil.sys/pagefile.sys/memory.dmp'
      command: 'bulk_extractor -o <outfolder> -x all -e base64 -e gzip -e zip -e rar -e hyberfile -e httplogs -e pdf -e evtx -e winlnk -e winpe -e winprefetech <infile>'
    - description: 'Carve NTFS'
      command: 'ntfsundelete /dev/loopX -s -p 100 -m "<file_pattern.ext>" -t 1m && ntfsundelete /dev/loopX -i <inode> -d <outfolder>'


